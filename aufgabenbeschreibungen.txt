cartpole_env.py:
	update_state gehts mit der Physik los, returnt aus kraft und aktuellen zustand position
	
Zur aufgabenbeschreibung: lernen nahand von einem links  und rechts schwung wies weiter geht

1024 test und training aus beispiele text
Mit training input und output gp für zeitreihendaten zu machen, stichwort regressoren im Buch - man fragt sich nach den Features wo sind die, die sind lagged-system-states also zurückversetzte datenpunkte (kraft zum vorherigen zeitpunkt mit ableitungen daraus zu bauen) mit trainingsdaten machen und dann mit testdaten abgleichen
Seite im Buch wo Modelle dazu erklärt werden: Seite 29 Buch pdf 45
wenn nfir modell nicht funktioniert gehts mit dem narx-modell auf jeden Fall: zusätzlich vorhanden die Output
erstes Modell y ist nicht in den Features dabei, bei narx ist bei den regressoren auch tatsächlicher output dabei, mit output auf output mappen funktioniert typischerweise gut

Damit muss ich mir feature matrix bauen: daten (zeitreihendaten) input und output nehmen, man bekommt auch wieder zeitreihendaten (was für regressoren, was für kernelfunktionen) im regression example
GPRat macht genau des als Entry in diese Thematik
load_data in execute.py generiert die Daten gleich
in utils.py: daten reinladen, größe 1024 reinladen, anzahl regressoren (das ist non-finite linear response)
Prinzip: ich bin an stelle i, will feature vec für stelle i mit 4 regressoren, gibt vec mit länge aus mit Zeitpunkt i, i-1, i-2 ... gpytorch reference
run.sh mit python3 anpassen

prediction ohne var ist diese inverse Seite 12 Buch, covariance matrix invertieren und mit output daten multiplozieren

Dazuimplementieren Visualisierung wie im gpytroch regression example: mean, uncertainty... damit gefühl bekommen wie man gp auf daten fitted und was sinnvolles rauskommt



Linus:
Environment und RL Agent als NN, agieren im Feedback Loop, Actions sind ansteuerung vom Kart
Env spuckt neuen Zustand aus, der wird in Agent gefüttert und agiert damit wieder
Im Training ist Loop auch so, zusätzlich Reward wie gut (hier cos aus Winkel halbe) winkel 0 ist ideal mit reward 1, zusätlich soll wagen sich in Mitte befinden. RL algo versucht akkumulativ Reward zu maximieren zusammenhängend trajectory
Deep-Q-Learning für Training (Wikiartikel) Idee: Tabelle versuchen zu lernen, Formel aus algo abschnitt wie man einzelne Zellen updatet, hoffen das Werte iwo hin konvergieren, deepq ersetzt diese Tabelle durch NN, GP ersetzt auch die Tabelle
Idealfall minimale Korrekturbewegung nach Aufschwingen, sollte mit drin sein

Code: 9 discrete actions werden auf ne Kraft gemapped, cartpole_env Zeile 167 0-3 sind verschieden starke kräfte in links, 4 keine kraft, 5-8 in andere Richtung -> das ist das was policy entscheidet. Gen_video aus 49 fragt Policy was gemacht werden soll, observation basierend auf aktueller Position 
Eingreifen: funktion schreiben die die Werte 0-8 an zeile 49 zurückgibt auf dem was gelernt wurde und das dann integrieren

Link Tensorflow: algo ist dort schon implementiert, nur NN ersetzen durch GP
Link Pytorch reinforcement_learning q-learning

Theoretisch Anpassen von Kraftstufen möglich, oder nur zwei Kräfte für Anfang, was für Anfang auch ideal wäre erstmal upright halten da deutlich einfacher

Wenn richtig gemacht ist GP nur Matrix  Multiplikation 
https://en.wikipedia.org/wiki/Q-learning
https://www.tensorflow.org/agents/api_docs/python/tf_agents/agents/DqnAgent
https://docs.pytorch.org/tutorials/intermediate/reinforcement_q_learning.html


Gaussian Process Regression (GPR) kann auch mit PyTorch implementiert werden. Besonders die Bibliothek `gpytorch` bietet eine Implementierung.

Die Systemidentifikation im Kontext von GPR ist grundsätzlich eine Regressionsaufgabe, bei der schließlich kontinuierliche Vorhersagen erstellt werden 
sollen.

Wenn man nur lineare Funktionen (Actions) modellieren möchte, kann man auch einen Gaussian Process für die Classification verwenden. Eine Alternative 
besteht darin, für jede einzelne Ausgangsvariable (z.B. Kraft in einer bestimmten Richtung), einen eigenen Gaussian Process aufzusetzen und dann deren 
maximalen Wert als Vorhersage zu nutzen.

Zum Anfang sollte man versuchen, eine Software mit GPs aufzubauen, die ohne vorgegebene Parameter- oder Kernelschem funktioniert – diese Parameter und 
der Kernel sollten völlig egal sein und nur optimiert werden, wenn es notwendig ist.

Der Timestep muss aus der Funktion auch übergeben werden. Die vier beobachtbaren Werte (Observation) umfassen die Position sowie Geschwindigkeit und 
Winkelgeschw.

Für das Generieren von Trainingsdaten kann man vorgeben, welche Actionschritte im Training berücksichtigt werden sollen. Man muss dann Werte eingeben 
und daraus Kraftprofile usw. generieren können.

Die Motivation dahinter ist u.a., dass Trainingszeiten im Kontext von Stromverbrauch begrenzt sind. Ideal wäre es daher, eine Vorhersagemethode zu 
haben, die nur kurze Trainingszeiten benötigt – mehr trainingsbezogene Daten wären dann auch ein gutes Ergebnis.

In `utils.py` ist bereits eine Mean-Funktion implementiert. Hyperparameter und Längenskalen (lengthscale) sind zusätzlich zu den Kernen vorgegeben. Wie 
auf Seite 23 dargestellt, wird die Funktion `helman` gezeigt, wie man eine Mean-Funktion und einen Kernel mit ihren Hyperparametern (`k`, 
`hyperparameter_l`) definiert.

Der Längenskala-Parameter `l` ist der wichtigste Hyperparameter. In den Trainingsdaten aus Methode 3.9 (in `utils.py`, Zeile kommentiert) sollte man das 
berücksichtigen.

Die Likelihood-Rauschkomponente (`likelihood noise`) wird schließlich auf die Diagonale der Kovarianzmatrix angewandt, um etwas Rauschen einzubringen – 
wie in `utils`? Die drei (Parameter?), Seite 28 oben. L=1 ist der ideale Fall für diese drei Parameter.

Die Gleichung aus Methode 3.9 auf Seite 25 (gleichung 3.9) ist auskommentiert und dient als Grundgerüst, falls man Hyperparameter nicht geschickt wählen 
kann – sie könnte später importiert werden, z.B. aus der Train-Methode.

Die eigentliche Vorhersage (`prediction`) ist das Ziel; dabei handelt es sich um eine kontinuierliche Ausgabe (continuous output). Die Funktion in 
`utils` für die Vorhersage entspricht im Wesentlichen Gleichung 3.7 und führt tatsächlich nur die Konstruktion der Kovarianzmatrix (`K`) und des 
Basisvektors (`b`) durch.

Mit `gpytorch` kann man auch den Kernel selbst anpassen oder erweitern.

Für Plots sollte man wie im Paper dargestellt, aus PyTorch (statt GPyTorch) arbeiten. Die Confidence-Region wird als Varianz visualisiert.

Die Systemidentifikation für das Generieren eines Regressors ist in einem Buch beschrieben; zusätzlich zu den 4 bekannten Parametern sollten auch die 
Parameter des vorherigen Zeitschritts (TimeStep?) berücksichtigt werden. Man könnte dies sogar dreimal machen – mit unterschiedlichen Featuremengen: am 
Anfang nur 4 Features, dann bei schlechten Werten mehr (z.B. 8).

Derzeit ist eine Nichtlineare Autoregressive (NAR) Implementierung (NFIR?) als Regressor vorhanden.